{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ラビット☆チャレンジ 提出レポート"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【a】応用数学"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参考図書"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[徹底攻略ディープラーニングE資格エンジニア問題集 スキルアップAI株式会社 小縣 信也](https://www.amazon.co.jp/gp/product/4295009180/ref=ppx_yo_dt_b_asin_title_o03_s00?ie=UTF8&psc=1)  \n",
    "[Think Stats 第2版 ―プログラマのための統計入門 Allen B. Downey](https://www.amazon.co.jp/gp/product/4873117356/ref=ppx_yo_dt_b_asin_title_o06_s00?ie=UTF8&psc=1)  \n",
    "[Think Bayes ―プログラマのためのベイズ統計入門 Allen B. Downey](https://www.amazon.co.jp/gp/product/4873116945/ref=ppx_yo_dt_b_asin_title_o06_s00?ie=UTF8&psc=1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第1章 線形代数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 目標"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1)固有値・固有ベクトルの求め方を確認する。  \n",
    "2)固有値分解について理解を深める。  \n",
    "3)特異値・特異ベクトルの概要を知る。  \n",
    "4)特異値分解の概要を知る。    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1)固有値・固有ベクトルの求め方を確認する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "・固有値・固有ベクトルとは？  \n",
    "  \n",
    "ある行列Aに対して、以下のような式が成り立つような、  \n",
    "特殊なベクトル$\\boldsymbol{x}$と、右辺の係数$\\lambda$がある。  \n",
    "$$\n",
    "A\\boldsymbol{x} = \\lambda\\boldsymbol{x}\n",
    "$$\n",
    "行列Aとその特殊なベクトル$\\boldsymbol{x}$の積は、ただのスカラー数$\\lambda$と  \n",
    "その特殊なベクトル$\\boldsymbol{x}$との積と同じ値になる!  \n",
    "\n",
    "この特殊なベクトル$\\boldsymbol{x}$とその係数$\\lambda$を行列Aに対する固有ベクトル、固有値という。  \n",
    "  \n",
    "m*mの正方行列の場合、固有値は最大m個ある。  \n",
    "固有ベクトルは、m次元ベクトルで、m個の成分の比率が一定で、成分は定数倍となる。\n",
    "\n",
    "・どのような嬉しいことがあるか。  \n",
    "固有値分解、特異値分解に利用することによって、累乗の計算処理の負荷が減る、データ圧縮に応用出来る。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "・求め方\n",
    "$$\n",
    "A= \\begin{pmatrix}\n",
    "1 & 2 \\\\\n",
    "4 & 3\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\boldsymbol{x}= \\begin{pmatrix}\n",
    "x_{1} \\\\\n",
    "x_{2}\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "とする\n",
    "\n",
    "$$\n",
    "A\\boldsymbol{x} = \\lambda\\boldsymbol{x}\n",
    "$$\n",
    "\n",
    "$$(A-\\lambda \\boldsymbol{e})\\boldsymbol{x} = \\boldsymbol{0}$$\n",
    "\n",
    "ここで、$\\boldsymbol{x} \\neq \\boldsymbol{0}$であることは自明である  \n",
    "よって  \n",
    "$$\\left|A-\\lambda \\boldsymbol{e} \\right|　= \\boldsymbol{0}$$\n",
    "行列式の計算をすると\n",
    "$$\\left|\\begin{pmatrix}\n",
    "1 & 4 \\\\\n",
    "2 & 3\\end{pmatrix}-\\lambda\\begin{pmatrix}\n",
    "1 & 0 \\\\\n",
    "0 & 1\\end{pmatrix}\\right|$$\n",
    "$$=\\left|\\begin{pmatrix}\n",
    "1 & 4 \\\\\n",
    "2 & 3\\end{pmatrix}-\\begin{pmatrix}\n",
    "\\lambda & 0 \\\\\n",
    "0 & \\lambda\\end{pmatrix}\\right|$$\n",
    "$$=\\begin{vmatrix}\n",
    "1-\\lambda & 4 \\\\\n",
    "2 & 3-\\lambda\\end{vmatrix}=0$$  \n",
    "$$(1-\\lambda )(3-\\lambda) - 4*2 = 0$$\n",
    "この二次方程式を因数分解する\n",
    "$$3 - 4\\lambda + \\lambda^2 -8 = 0$$\n",
    "$$\\lambda^2-4\\lambda -5 = 0$$\n",
    "$$(\\lambda+1)(\\lambda-5) = 0$$\n",
    "$$\\lambda　=  5 , -1$$\n",
    "ここで  \n",
    "$$A\\boldsymbol{x} = \\lambda\\boldsymbol{x}$$\n",
    "$$\\begin{pmatrix}\n",
    "1 & 2 \\\\\n",
    "4 & 3\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "x_{1} \\\\\n",
    "x_{2}\n",
    "\\end{pmatrix}\n",
    "= \\lambda\\begin{pmatrix}\n",
    "x_{1} \\\\\n",
    "x_{2}\n",
    "\\end{pmatrix}$$\n",
    "の$\\lambda$に先で求めた値を代入する  \n",
    "$\\lambda=5$を代入すると  \n",
    "$$\\begin{pmatrix}\n",
    "1 & 4 \\\\\n",
    "2 & 3 \\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "x_{1} \\\\\n",
    "x_{2}\n",
    "\\end{pmatrix}\n",
    "= 5\\begin{pmatrix}\n",
    "x_{1} \\\\\n",
    "x_{2} \\end{pmatrix}$$  \n",
    "1行目から  \n",
    "$$x_{1} + 4x_{2} = 5 x_{1}$$\n",
    "x_{1} = x_{2}$$\n",
    "$$\n",
    "よって\n",
    "$$x_{1} = x_{2}$$\n",
    "$\\lambda=-1$を代入すると  \n",
    "$$\\begin{pmatrix}\n",
    "1 & 4 \\\\\n",
    "2 & 3\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "x_{1} \\\\\n",
    "x_{2}\\end{pmatrix}\n",
    "= -1\\begin{pmatrix}\n",
    "x_{1} \\\\\n",
    "x_{2}\\end{pmatrix}$$\n",
    "1行目から  \n",
    "$$x_{1} + 4x_{2} = -x_{1}$$\n",
    "$$2x_{1} = -4x_{2}$$\n",
    "$$x_{1} = -2x_{2}$$\n",
    "よって  \n",
    "$$x_{1} = -2x_{2}$$\n",
    "したがって  \n",
    "固有値$\\lambda=5$のとき\n",
    "固有ベクトル$\\boldsymbol{x}= \\begin{pmatrix}\n",
    "1 \\\\\n",
    "1\n",
    "\\end{pmatrix}$の定数倍  \n",
    "固有値$\\lambda=-1$のとき\n",
    "固有ベクトル$\\boldsymbol{x}= \\begin{pmatrix}\n",
    "2 \\\\\n",
    "-1\n",
    "\\end{pmatrix}$の定数倍  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2)固有値分解について理解を深める。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正方行列Aが固有値$\\lambda_{1}$,$\\lambda_{2}$,...と\n",
    "固有ベクトル$\\boldsymbol{v}_{1}$,$\\boldsymbol{v}_{2}$,...を持ったとする。  \n",
    "この固有値を対角線上に並べた行列（それ以外の成分は０）  \n",
    "$$\n",
    "\\Lambda=\n",
    "\\begin{pmatrix}\n",
    "\\lambda_{1}&&\\\\\n",
    "&\\lambda_{2}&\\\\\n",
    "&&\\ddots\n",
    "\\end{pmatrix}\\\\\n",
    "$$\n",
    "と、それに対応する固有ベクトルを並べた行列  \n",
    "$$\n",
    "V=\n",
    "\\begin{pmatrix}\n",
    "\\boldsymbol{v}_{1}&\\boldsymbol{v}_{1}&\\cdots\n",
    "\\end{pmatrix}\\\\\n",
    "$$\n",
    "を用意したとき、それらは、  \n",
    "$$AV=V\\Lambda$$  \n",
    "と関係付けられる。したがって  \n",
    "$$A=V\\Lambda V^{-1}$$\n",
    "と変形できる。このように正方行列を上述のような3つの行列の席に変換することを固有値分解という。  \n",
    " この変換によって行列の累乗計算が容易になる等の利点がある。  \n",
    "   \n",
    "累乗の例：  \n",
    "$$\n",
    "A^{2}=(V\\Lambda V^{-1})^{2}\\\\  \n",
    "=(V\\Lambda V^{-1})(V\\Lambda V^{-1})\\\\  \n",
    "=V\\Lambda V^{-1}V\\Lambda V^{-1}\\\\  \n",
    "=V\\Lambda^{2} V^{-1}  \n",
    "$$\n",
    "  \n",
    "$$A^{3}=(V\\Lambda V^{-1})^{3}\\\\  \n",
    "=(V\\Lambda V^{-1})(V\\Lambda V^{-1})(V\\Lambda V^{-1})\\\\  \n",
    "=V\\Lambda V^{-1}V\\Lambda V^{-1}V\\Lambda V^{-1}\\\\  \n",
    "=V\\Lambda^{3} V^{-1}  \n",
    "$$\n",
    "\n",
    "$$A^{n}=(V\\Lambda V^{-1})^{n}\\\\  \n",
    "=V\\Lambda^{n} V^{-1}  \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3)特異値・特異ベクトルの概要を知る。4)特異値分解の概要を知る。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考になるページ:  \n",
    "[特異値分解-wikipedia](https://ja.wikipedia.org/wiki/%E7%89%B9%E7%95%B0%E5%80%A4%E5%88%86%E8%A7%A3)\n",
    "\n",
    "$U$ は m 行 m 列のユニタリ行列。  \n",
    "$V^{-1}$(V*と表記することも) は n 行 n 列のユニタリ行列 V の随伴行列（複素共役かつ転置行列）。  \n",
    "ベクトル$ \\boldsymbol{u}, \\boldsymbol{v}$ を、それぞれ σ の左特異ベクトル (left-singular vector) と右特異ベクトル (right-singular vector) と呼ぶ。\n",
    "\n",
    "正則行列ではない行列$M$に、固有値分解は出来ない。  \n",
    "似たような処理の特異値分解(singular value decomposition;SVD)なら出来る。\n",
    "$$\n",
    "M\\boldsymbol{v}=\\sigma\\boldsymbol{u}\\\\\n",
    "M^{T}\\boldsymbol{u}=\\sigma\\boldsymbol{v}\n",
    "$$\n",
    "**ここで転置行列を使うところがポイント！**  \n",
    "\n",
    "  \n",
    "このような特殊な単位ベクトルがあるならば、特異値分解出来る。\n",
    "$$\n",
    "M=USV^{-1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 特異値の求め方"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "MV=US\\\\\n",
    "M^{T}U=VS^{T}\n",
    "$$\n",
    "V、Uのそれぞれの逆行列を右辺の右から掛ける。  \n",
    "  \n",
    "$$\n",
    "M=USV^{-1}\\\\\n",
    "M^{T}=VS^{T}U^{-1}\n",
    "$$\n",
    "  \n",
    "これらの積は  \n",
    "$$\n",
    "MM^{T}=USV^{-1}VS^{T}U^{-1}=USS^{T}U^{-1}\n",
    "$$  \n",
    "つまり$MM^{T}$を固有値分解すれば、その左特異ベクトルと特異値の2乗が求められる。  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 特異値分解の利用例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像のデータ圧縮、擬似逆行列の計算等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第2章 確率・統計"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 目標"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1)条件付き確率について理解を深める。  \n",
    "2)ベイズ 則の概要を知る。  \n",
    "3)期待値・分散の求め方を確認する。  \n",
    "4)様々な確率分布の概要を知る。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考サイト  \n",
    "[統計Web-統計学の時間](https://bellcurve.jp/statistics/course/) このサイトのおかげで統計検定２級取得できた。   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0)覚えておきたいこと"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-頻度確率(客観確率)  \n",
    " ・発生する頻度  \n",
    "-ベイズ 確率  \n",
    " ・信念の度合い  \n",
    " ・ex.「あなたは40%の確率でインフルエンザです」という診断  \n",
    " ・オライリーから[『Think Bayes』](https://www.amazon.co.jp/Think-Bayes-%E2%80%95%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%9E%E3%81%AE%E3%81%9F%E3%82%81%E3%81%AE%E3%83%99%E3%82%A4%E3%82%BA%E7%B5%B1%E8%A8%88%E5%85%A5%E9%96%80-Allen-Downey/dp/4873116945/ref=sr_1_1?__mk_ja_JP=%E3%82%AB%E3%82%BF%E3%82%AB%E3%83%8A&dchild=1&keywords=think+bayes&qid=1609484573&sr=8-1)が出版されているので、余裕が出来たら読んでみたい。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1)条件付き確率について理解を深める。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "条件付き確率とは背景情報に基づいた確率である。  \n",
    "事象X=xが与えられたもとで、事象Y=yとなる確率は以下の式となる。  \n",
    "$$\n",
    "P(Y=y|X=x)=\\frac{P(Y=y, X=x)}{P(X=x)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "独立な事象の同時確率  \n",
    "上記の事象X、Yが独立である場合、同時に起こる確率は以下の式となる。\n",
    "$$\n",
    "P(X=x, Y=y)=P(X=x)P(Y=y)=P(Y=y, X=x)\n",
    "$$\n",
    "XとYのどちらが先でも後でも同じになる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2)ベイズ 則の概要を知る。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T07:18:20.572139Z",
     "start_time": "2021-01-01T07:18:20.558796Z"
    }
   },
   "source": [
    "事象X=xが与えられたもとで、事象Y=yに対して、\n",
    "$$\n",
    "P(Y=y|X=x)=\\frac{P(Y=y, X=x)}{P(X=x)}\n",
    "$$\n",
    "両辺に$P(X=x)$を掛ける。\n",
    "\n",
    "$$\n",
    "P(Y=y|X=x)P(X=x)=P(Y=y, X=x)\n",
    "$$\n",
    "\n",
    "変形して両辺を入れ替えると  \n",
    "\n",
    "$$\n",
    "P(Y=y, X=x)=P(X=x)P(Y=y|X=x)\n",
    "$$\n",
    "\n",
    "このような変形を「乗法定理」という。  \n",
    "X,Yを入れ替えて、次のようにも書くことができる。  \n",
    "$$\n",
    "P(X=x|Y=y)P(Y=y)=P(Y=y|X=x)P(X=x)\n",
    "$$\n",
    "\n",
    "ここで以下の式に、上記の式を代入する\n",
    "$$\n",
    "P(Y=y|X=x)=\\frac{P(Y=y, X=x)}{P(X=x)}\n",
    "$$\n",
    "$$\n",
    "P(Y=y|X=x)=\\frac{P(X=x|Y=y)P(Y=y)}{P(X=x)}=\\frac{P(Y=y)P(X=x|Y=y)}{P(X=x)}\n",
    "$$\n",
    "これが「ベイズ の定理」である。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3)期待値・分散の求め方を確認する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-期待値の求め方  \n",
    " ・離散分布の場合  \n",
    "$$\n",
    "E(f)=\\sum_{k=1}^{n}P(X=x_{k})f(X=x_{k})\n",
    "$$  \n",
    " ・連続分布の場合  \n",
    "$$\n",
    "E(f)=\\int P(X=x)f(X=x)dx\n",
    "$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-分散の求め方  \n",
    " ・データの散らばり具合  \n",
    " ・データの各々の値が、期待値からどれだけずれているのかを二乗して平均したもの\n",
    "$$\n",
    "Var(f)=E((f(X=x)-E(f))^{2})\\\\=E(f(X=x)^{2})-(E(f))^{2}\n",
    "$$  \n",
    "「二乗の期待値から、期待値の二乗を引く」と覚える。  \n",
    "-分散の求め方  \n",
    " ・2つのデータ系列の傾向の違い    \n",
    " ・正の値を取れば似た傾向  \n",
    " ・負の値を取れば逆の傾向  \n",
    " ・ゼロを取れば関係性に乏しい  \n",
    "$$\n",
    "Cov(f,g)=E((f(X=x)-E(f))(g(Y=y)-E(g)))\\\\=E(fg)-E(f)E(g)\n",
    "$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4)様々な確率分布の概要を知る。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-ベルヌーイ 分布  \n",
    "・コイントスのイメージ  \n",
    "・コインの裏と表で出る割合が等しくなくても扱える  \n",
    "・以下の式では、xは裏か表かの結果(x=0, 1)、$\\mu$ が表である確率\n",
    "$$\n",
    "P(x|\\mu)=\\mu ^{x}(1-\\mu)^{1-x}\n",
    "$$\n",
    "\n",
    "$$\n",
    "E(X) =\\mu\n",
    "$$\n",
    "\n",
    "$$\n",
    "V(X)=p(1-p)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-マルチヌーイ(カテゴリカル)分布  \n",
    "・サイコロを転がすイメージ  \n",
    "・各面の出る割合が等しくなくとも扱える  \n",
    "・式は、ベルヌーイ 分布とほぼ同様だが、xの取りうる値が3通り以上ある  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-二項分布  \n",
    "・ベルヌーイ 分布の多試行版  \n",
    "・結果の出方の組み合わせを考慮する  \n",
    "$$\n",
    "P(x| \\lambda,n)=\\frac{n!}{x!(n-x)!}\\lambda^{x}(1-\\lambda)^{n-x}\n",
    "$$\n",
    "\n",
    "$$\n",
    "E(X) = np\n",
    "$$\n",
    "\n",
    "$$\n",
    "V(X) = np(1 - p)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-ガウス分布(正規分布)  \n",
    "・釣鐘型の分布  \n",
    "・多くの検定、推定で仮定される  \n",
    "・図形で言うと、正三角形のような存在  \n",
    "$$\n",
    "f(x) = \\frac{1}{\\sqrt{2\\pi \\sigma^2}} \\exp \\left(-\\frac{(x - \\mu)^2}\n",
    "{2\\sigma^2} \\right) \\hspace{20px} (-\\infty < x < \\infty)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第3章 情報理論"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 目標"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1)自己情報量・シャノンエントロピーの定義を確認する。  \n",
    "2)KLダイバージェンス・交差エントロピーの概要を知る。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考サイト  \n",
    "[情報量 - Wikipedia](https://ja.wikipedia.org/wiki/%E6%83%85%E5%A0%B1%E9%87%8F)   \n",
    "[§５　MemCalcとエントロピー](http://www.gms-jp.com/MemCalc_HP/5-1.htm)  \n",
    "[自己情報量からKLダイバージェンス超えて交差エントロピーまでをまとめる - Qiita](https://qiita.com/g-k/items/21574795b6a8db51f912)    \n",
    "[情報理論の基礎～情報量の定義から相対エントロピー、相互情報量まで～ | Logics of Blue](https://logics-of-blue.com/information-theory-basic/)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1)自己情報量・シャノンエントロピーの定義を確認する。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-自己情報量  \n",
    "・情報がもたらす系の状態の不確定さの減少分をその情報の自己情報量と言う。  \n",
    "・情報の発生確率が低いほど自己情報量が多い。  \n",
    "・対数の底が２のとき、単位はビット(bit)  \n",
    "・対数の底がネイピア数eのとき、単位はナット(nat)  \n",
    "・自己情報量の計算式\n",
    "$$\n",
    "I(x)=-log(P(x))=log(W(x))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "・選択情報量（自己エントロピー）と平均情報量（エントロピー）  \n",
    ">それぞれのできごとの情報量だけでなく、それらのできごとの情報量の平均値も情報量と呼ぶ。両者を区別する場合には、前者を選択情報量（自己エントロピーとも）、後者を平均情報量（エントロピーとも）と呼ぶ。  \n",
    "\n",
    "[情報量 - Wikipedia](https://ja.wikipedia.org/wiki/%E6%83%85%E5%A0%B1%E9%87%8F#%E9%81%B8%E6%8A%9E%E6%83%85%E5%A0%B1%E9%87%8F%EF%BC%88%E8%87%AA%E5%B7%B1%E3%82%A8%E3%83%B3%E3%83%88%E3%83%AD%E3%83%94%E3%83%BC%EF%BC%89%E3%81%A8%E5%B9%B3%E5%9D%87%E6%83%85%E5%A0%B1%E9%87%8F%EF%BC%88%E3%82%A8%E3%83%B3%E3%83%88%E3%83%AD%E3%83%94%E3%83%BC%EF%BC%89)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-シャノンエントロピー  \n",
    "・平均情報量、シャノン情報量、情報論のエントロピーとも  \n",
    "・微分エントロピーとも言うが、微分しているわけではない    \n",
    "・自己情報量の期待値  \n",
    "・**確率変数のランダム性の指標**としてよく用いられる()\n",
    "・$\\Omega$を、台が有限集合である確率空間とする。$\\Omega$上の確率分布Pが与えられたとき、各事象$A\\in \\Omega$の選択情報量$-\\log P(A)$の期待値   \n",
    "$$\n",
    "H(A)=E(I(A))=-E(log(P(A)))=-\\sum_{A \\in \\Omega}(P(A)log(P(A)))\n",
    "$$\n",
    "をPのエントロピーと呼ぶ。\n",
    "\n",
    "・エントロピーの基本的性質  \n",
    ">1.情報量は確率だけによって決まる。  \n",
    "2.情報量は非負の値または無限大を取る。  \n",
    "3.nビットのビット列の空間（情報源）から（一様ランダムとは限らない方法で）ランダムにビット列を選んだときのエントロピーは、n以下4.になる。エントロピーがnになる必要十分条件は、ビット列が一様ランダムに選ばれることである。  \n",
    "5.確率変数XとYが独立である必要十分条件は、${\\displaystyle H(X)+H(Y)=H(X,Y)}$が成立することである。\n",
    "\n",
    "\n",
    "[情報量 - Wikipedia](https://ja.wikipedia.org/wiki/%E6%83%85%E5%A0%B1%E9%87%8F#%E3%82%A8%E3%83%B3%E3%83%88%E3%83%AD%E3%83%94%E3%83%BC%E3%81%AE%E5%9F%BA%E6%9C%AC%E7%9A%84%E6%80%A7%E8%B3%AA)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2)KLダイバージェンス・交差エントロピーの概要を知る。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-KLダイバージェンス  \n",
    "・相対エントロピー、KL情報量とも  \n",
    "・情報量を異なる確率分布で見る。確率分布Pの情報量を確率分布Qで見るならば、それぞれの確率分布で情報量を求めて差を求める。差を求める際に引き算を行うが、対数の引き算は割り算になることに注意する！  \n",
    "・\n",
    ">これは確率分布の差異を表す指標といえます。分布間擬距離とも呼ばれます。\n",
    "「擬」という言葉がある通り、正確な距離とは言えないところはありますが、確率分布ごとの違いを見るのによく使われます。  \n",
    "\n",
    "[情報理論の基礎～情報量の定義から相対エントロピー、相互情報量まで～ | Logics of Blue](https://logics-of-blue.com/information-theory-basic/)  \n",
    "・式  \n",
    "$$\n",
    "D_{KL}(P\\|Q)=\\mathbb{E}_{x \\text{~} P}\\begin{bmatrix}\n",
    "log \\frac{P(x)}{Q(x)}\n",
    "\\end{bmatrix}=\\mathbb{E}_{x \\text{~} P}\\begin{bmatrix}\n",
    "log {P(x)} \\text{-} log{Q(x)}\n",
    "\\end{bmatrix}\n",
    "=-\\sum_{x}P(x)((-log Q(x))- (-log P(x)))\\\\\n",
    "=-\\sum_{x}P(x)(log P(x)- log Q(x))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-交差エントロピー(クロスエントロピー)  \n",
    "・KLダイバージェンスの一部分を取り出したもの  \n",
    "・**Qについての情報量をPの分布で平均している**  \n",
    "・分類の損失関数に用いる  \n",
    "・式\n",
    "$$\n",
    "H(P,Q)=H(P)+D_{KL}(P \\| Q)=-\\mathbb E_{x \\text{~} P} log Q(x) = - \\sum_{x} P(x)logQ(x)  \n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
